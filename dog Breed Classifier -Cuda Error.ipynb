{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks for a Dog Breed Identifier\n",
    "\n",
    "\n",
    "\n",
    "![Sample Dog Output](images/sample_dog_output.png)\n",
    "\n",
    "---\n",
    "<a id='step0'></a>\n",
    "## Step 0: Import Datasets\n",
    "\n",
    "Make sure that you've downloaded the required human and dog datasets:\n",
    "* Download the [dog dataset](https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/dogImages.zip).  Unzip the folder and place it in this project's home directory, at the location `/dogImages`. \n",
    "\n",
    "* Download the [human dataset](https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/lfw.zip).  Unzip the folder and place it in the home diretcory, at location `/lfw`.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='step3'></a>\n",
    "Create a CNN to Classify Dog Breeds (from Scratch)\n",
    "\n",
    "\n",
    "\n",
    "### (IMPLEMENTATION) Specify Data Loaders for the Dog Dataset\n",
    "\n",
    "Use the code cell below to write three separate [data loaders](http://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader) for the training, validation, and test datasets of dog images (located at `dogImages/train`, `dogImages/valid`, and `dogImages/test`, respectively).  You may find [this documentation on custom datasets](http://pytorch.org/docs/stable/torchvision/datasets.html) to be a useful resource.  If you are interested in augmenting your training and/or validation data, check out the wide variety of [transforms](http://pytorch.org/docs/stable/torchvision/transforms.html?highlight=transform)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sampler import ImbalancedDatasetSampler\n",
    "import os\n",
    "from torchvision import datasets\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "##from torch.utils.data.sampler import Sampler\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "                               transforms.Resize(255),\n",
    "                               transforms.CenterCrop(224), \n",
    "                               transforms.RandomHorizontalFlip(),\n",
    "                               transforms.RandomRotation(10),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize(\n",
    "                               [0.5,0.5,0.5],\n",
    "                               [0.5,0.5,0.5])])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "                               transforms.Resize(255),\n",
    "                               transforms.CenterCrop(224), \n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize(\n",
    "                               [0.5,0.5,0.5],\n",
    "                               [0.5,0.5,0.5])])\n",
    "\n",
    "### TODO: Write data loaders for training, validation, and test sets\n",
    "## Specify appropriate transforms, and batch_sizes\n",
    "img_path= (r'D:\\deep-learning-pytorch\\project-dog-classification\\dogImages')\n",
    "\n",
    "train_data = datasets.ImageFolder(root = img_path +'/train' , transform = train_transform )\n",
    "valid_data = datasets.ImageFolder(root = img_path +'/valid' , transform = test_transform )\n",
    "test_data = datasets.ImageFolder(root = img_path +'/test'   , transform = test_transform )\n",
    "\n",
    "###***train_loader = torch.utils.data.DataLoader(train_data,batch_size = 42,shuffle = True)\n",
    "train_loader = torch.utils.data.DataLoader(train_data,batch_size = 42,shuffle = True,drop_last=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_data, batch_size = 42,shuffle = True,drop_last=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = 42,shuffle = True,drop_last=True)\n",
    "\n",
    "loaders= {}\n",
    "loaders['train'] = train_loader\n",
    "loaders['valid'] = valid_loader\n",
    "loaders['test']  = test_loader\n",
    "\n",
    "loaders_scratch = loaders\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (IMPLEMENTATION) Model Architecture\n",
    "\n",
    "Create a CNN to classify dog breed.  Use the template in the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "# define the CNN architecture\n",
    "class Net(nn.Module):\n",
    "    ### TODO: choose an architecture, and complete the class\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        ## Define layers of a CNN\n",
    "        self.Conv1 =  nn.Conv2d(3,64,3,1)\n",
    "        self.Conv2 =  nn.Conv2d(64,64,3,1)\n",
    "        self.pool1 = nn.MaxPool2d(2,2)\n",
    "        self.Conv3 = nn.Conv2d(64,128,3,1)\n",
    "        self.Conv4 = nn.Conv2d(128,128,3,1)\n",
    "        self.pool2 = nn.MaxPool2d(2,2)\n",
    "        self.Conv5 = nn.Conv2d(128,256,3,1)\n",
    "        self.Conv6 = nn.Conv2d(256,256,3,1)\n",
    "        #self.Conv7 = nn.Conv2D(256,256,3,1)\n",
    "        self.pool3 = nn.MaxPool2d(2,2)\n",
    "        self.Conv8 = nn.Conv2d(256,512,3,1)\n",
    "        self.pool4 = nn.MaxPool2d(2,2)\n",
    "        self.Conv9 = nn.Conv2d(512,512,3,1)\n",
    "        self.pool5 = nn.MaxPool2d(2,2)\n",
    "        #self.Conv10 = nn.Conv2d(512,512,3,1)\n",
    "        self.FC1 =   nn.Linear(512*4*4,1024)\n",
    "        self.FC2 = nn.Linear(1024,512)\n",
    "        self.FC3 = nn.Linear(512,133)\n",
    "        \n",
    "        ##Dropout of 20%\n",
    "        \n",
    "        self.Dropout = nn.Dropout(p=0.2)\n",
    "\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        ## Define forward behavior\n",
    "        x = self.Conv1(x)\n",
    "        x = self.Conv2(x)\n",
    "        x = F.relu(x) ######\n",
    "        x = self.pool1(x)\n",
    "        x = self.Conv3(x)\n",
    "        x = self.Conv4(x)\n",
    "        x = F.relu(x) ######\n",
    "        x = self.pool2(x)\n",
    "        x = self.Conv5(x)\n",
    "        x = self.Conv6(x)\n",
    "        x = F.relu(x) ######\n",
    "        x = self.pool3(x)\n",
    "        x = self.Conv8(x)\n",
    "        x = self.pool4(x)\n",
    "        x = self.Conv9(x)\n",
    "        x = self.pool5(x)\n",
    "        # flatten image input\n",
    "        #print(x.shape)\n",
    "        x = x.reshape(-1, 512*4*4)\n",
    "        x = self.FC1(x) ## added relu\n",
    "        x = self.Dropout(x) \n",
    "        x = self.FC2(x) ## added relu\n",
    "        x = self.Dropout(x)\n",
    "        x = self.FC3(x)\n",
    "        x = F.log_softmax(x,dim=1)\n",
    "        return x\n",
    "    \n",
    "def weights_init_norm(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Linear') != -1:\n",
    "        n =m.in_features\n",
    "        y = 1.0/np.sqrt(n)\n",
    "        m.weight.data.normal_(0,y)\n",
    "        m.bias.data.fill_(0)\n",
    "\n",
    "#-#-#\n",
    "\n",
    "# instantiate the CNN\n",
    "model_scratch = Net()\n",
    "\n",
    "## Added this line\n",
    "model_scratch.apply(weights_init_norm)\n",
    "\n",
    "# move tensors to GPU if CUDA is available\n",
    "if use_cuda:\n",
    "    model_scratch.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify Loss Function and Optimizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from PIL import ImageFile\n",
    "import gc\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "### TODO: select loss function\n",
    "criterion_scratch = nn.NLLLoss()\n",
    "\n",
    "### TODO: select optimizer\n",
    "optimizer_scratch = optim.Adam(model_scratch.parameters(), lr= .0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (IMPLEMENTATION) Train and Validate the Model\n",
    "\n",
    "Train and validate your model in the code cell below.  [Save the final model parameters](http://pytorch.org/docs/master/notes/serialization.html) at filepath `'model_scratch.pt'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Id 20\n",
      "Batch Id 40\n",
      "Batch Id 60\n",
      "Batch Id 80\n",
      "Batch Id 100\n",
      "Batch Id 120\n",
      "Batch Id 140\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 496.38 MiB (GPU 0; 6.00 GiB total capacity; 3.87 GiB already allocated; 348.64 MiB free; 401.80 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-90bfa670d75b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;31m# train the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m model_scratch = train(18, loaders_scratch, model_scratch, optimizer_scratch, \n\u001b[1;32m---> 79\u001b[1;33m                       criterion_scratch, use_cuda, 'model_scratch.pt')\n\u001b[0m\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;31m# load the model that got the best validation accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-90bfa670d75b>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(n_epochs, loaders, model, optimizer, criterion, use_cuda, save_path)\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[1;31m## update the average validation loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_scratch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion_scratch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-cde41a40f34a>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[1;31m## Define forward behavior\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m######\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    318\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[1;32m--> 320\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    321\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 496.38 MiB (GPU 0; 6.00 GiB total capacity; 3.87 GiB already allocated; 348.64 MiB free; 401.80 MiB cached)"
     ]
    }
   ],
   "source": [
    "def train(n_epochs, loaders, model, optimizer, criterion, use_cuda, save_path):\n",
    "    \"\"\"returns trained model\"\"\"\n",
    "    # initialize tracker for minimum validation loss\n",
    "    valid_loss_min = np.Inf \n",
    "    \n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        # initialize variables to monitor training and validation loss\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        \n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        model.train()\n",
    "        for batch_idx, (image,label) in enumerate(loaders['train']):\n",
    "            # move to GPU\n",
    "            if use_cuda:\n",
    "                image,label = image.cuda(), label.cuda()\n",
    "            if (batch_idx +1) % 20 == 0:\n",
    "                print('Batch Id '+ str(batch_idx +1))\n",
    "            ## find the loss and update the model parameters accordingly\n",
    "            ## record the average training loss, using something like\n",
    "            ## train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
    "            optimizer_scratch.zero_grad()\n",
    "            output = model_scratch(image)\n",
    "            loss = criterion_scratch(output,label)\n",
    "            ##loss.backward(retain_graph=False)\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer_scratch.step()\n",
    "            ##****train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.item() - train_loss))\n",
    "            ##****torch.cuda.empty_cache() \n",
    "            ##print(train_loss)\n",
    "            #print(loss.item())\n",
    "            ##image,label = image.to('cpu'), label.to('cpu')\n",
    "            ##gc.collect()\n",
    "        ######################    \n",
    "        # validate the model #\n",
    "        ######################\n",
    "        model.eval()\n",
    "        validation_accuracy = 0.0\n",
    "        for batch_idx, (image,label) in enumerate(loaders['valid']):\n",
    "            # move to GPU\n",
    "            if use_cuda:\n",
    "                image,label = image.cuda(), label.cuda()\n",
    "            ## update the average validation loss\n",
    "            \n",
    "            output = model_scratch(image)\n",
    "            loss = criterion_scratch(output,label)\n",
    "            \n",
    "            prob = torch.exp(output)\n",
    "            _,class_pred = prob.topk(1, dim =1)\n",
    "            equals = class_pred== label.view(*class_pred.shape)\n",
    "            validation_accuracy += torch.mean(equals.type(torch.FloatTensor))            \n",
    "            \n",
    "            ##valid_loss = valid_loss + ((1 / (batch_idx + 1)) * (loss.data - valid_loss))\n",
    "            valid_loss = valid_loss + ((1 / (batch_idx + 1)) * (loss.item() - valid_loss))\n",
    "        # print training/validation statistics \n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "            epoch, \n",
    "            train_loss,\n",
    "            valid_loss\n",
    "            ))\n",
    "        ##Print Validation Accuracy\n",
    "        print('Validation Accuracy :::::: ' + str(validation_accuracy.item()*100/len(loaders['valid'])) + str(' %'))\n",
    "        \n",
    "        ## TODO: save the model if validation loss has decreased\n",
    "        if (valid_loss < valid_loss_min ):    \n",
    "            print('Saving Model')\n",
    "            torch.save(model.state_dict(), 'model_scratch.pt')\n",
    "            valid_loss_min = valid_loss \n",
    "    \n",
    "    # return trained model\n",
    "    return model\n",
    "\n",
    "\n",
    "# train the model\n",
    "model_scratch = train(18, loaders_scratch, model_scratch, optimizer_scratch, \n",
    "                      criterion_scratch, use_cuda, 'model_scratch.pt')\n",
    "\n",
    "# load the model that got the best validation accuracy\n",
    "model_scratch.load_state_dict(torch.load('model_scratch.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current memory allocated: 3457.95166015625\n",
      "max memory allocated: 3620.21240234375\n",
      "cached memory: 3700.875\n"
     ]
    }
   ],
   "source": [
    "print('current memory allocated: {}'.format(torch.cuda.memory_allocated() / 1024 ** 2))\n",
    "print('max memory allocated: {}'.format(torch.cuda.max_memory_allocated() / 1024 ** 2))\n",
    "print('cached memory: {}'.format(torch.cuda.memory_cached() / 1024 ** 2))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
